{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Problem_set_5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_B78e6kZn8U"
      },
      "source": [
        "## **1(a)** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnO-ipFiVSGy"
      },
      "source": [
        "\n",
        "**Softmax Function :**\n",
        "\n",
        "Softmax function is used as an activation fuction in output layers.Cross enthropy function is used in the softmax funtion.It keeps he values between 0 and 1 for activation.Morevover, sum of these values will be 1.\n",
        "Formula for softmax function can be given as \n",
        "</br>\n",
        "</br>\n",
        "\n",
        "$ p_{k} = \\frac{e^{fk}}{\\sum_{j}^{}e^{fC}}$\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "**Negative Log-Likelyhood (NLL):**\n",
        "\n",
        "The loss grows larger on every incorrect prediction, since the determined loss will be zero at that prediction and we sum the loss for all the correct predictions.Hence to optimize a loss function, NLL finds the local minima of that loss fucntion. It is inversely proportional to the no. of values. Negative Log-Likelyhood can be given as follows. \n",
        "</br>\n",
        "</br>\n",
        "$L_{y} = -log({y_{i}})$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtSBvhWGTKht"
      },
      "source": [
        "## **1(b)** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyXtc-AYQVlV"
      },
      "source": [
        "Suppose we are predicting a single continuous target variable t from\n",
        "a vector x of inputs (the extension to multiple targets is straightforward). We shall\n",
        "suppose that the conditional distribution p(t|x) is Gaussian, with an x-dependent\n",
        "mean given by the output of a neural network model y(x,w), and with precision\n",
        "(inverse variance) β\n",
        "</br>\n",
        "</br>\n",
        "p(t|x,w, β) = N(t|y(x,w), β\n",
        "−1).\n",
        "</br>\n",
        "</br>\n",
        "Similarly, we shall choose a prior distribution over the weights w that is Gaussian of the form\n",
        "</br>\n",
        "</br>\n",
        "p(w|α) = N(w|0, α−1I).\n",
        "</br>\n",
        "</br>\n",
        "For an i.i.d. data set of N observations x1, . . . , xN, with a corresponding set of target\n",
        "values D = {t1, . . . , tN}, the likelihood function is given by\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "\n",
        "p(D|w, β) =$\\prod$ n=1\n",
        "N(tn|y(xn,w), β\n",
        "−1)\n",
        "</br>\n",
        "</br>\n",
        "and so the resulting posterior distribution is then\n",
        "</br>\n",
        "</br>\n",
        "p(w|D, α, β) ∝ p(w|α)p(D|w, β). (5.164)\n",
        "</br>\n",
        "</br>\n",
        "which, as a consequence of the nonlinear dependence of y(x,w) on w, will be non-\n",
        "Gaussian.\n",
        "We can find a Gaussian approximation to the posterior distribution by using the\n",
        "Laplace approximation. To do this, we must first find a (local) maximum of the\n",
        "posterior, and this must be done using iterative numerical optimization. As usual, it\n",
        "is convenient to maximize the logarithm of the posterior, which can be written in the form\n",
        "</br>\n",
        "</br>\n",
        "\n",
        "ln p(w|D) = −α/2 wTw − β/2$\\sum_{n=1}^{N}$n=1{y(xn,w) − tn}^2 + const\n",
        "</br>\n",
        "</br>\n",
        "which corresponds to a regularized sum-of-squares error function. Assuming for\n",
        "the moment that α and β are fixed, we can find a maximum of the posterior, which\n",
        "we denote wMAP, by standard nonlinear optimization algorithms such as conjugate\n",
        "gradients, using error backpropagation to evaluate the required derivatives."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hukbmAKZkr4"
      },
      "source": [
        "# **2(a), 2(b), 2(c)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fr8hikh12Q-B"
      },
      "source": [
        "\n",
        "# Importing utility libraries\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import os\n",
        "import numpy as np\n",
        "import time\n",
        "import PIL\n",
        "from IPython import display\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gjrh40Iu3BVB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e5a217f9-d7ad-43f6-b23f-d69fdcbe82d0"
      },
      "source": [
        "# Splitting the dataset\n",
        "(X_train, y_train),(X_test, y_test ) = mnist.load_data()\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (60000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peR84JpurC_8"
      },
      "source": [
        "# Normalizing the dataset to between (-1, 1)\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
        "X_train = (X_train - 127.5) / 127.5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87gRs4Xqrvs1"
      },
      "source": [
        "# Creating the bathches and shuffling the dataset\n",
        "buffer_size = X_train.shape[0]\n",
        "batch = 128\n",
        "X_train = tf.data.Dataset.from_tensor_slices(X_train).shuffle(buffer_size).batch(batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "90Mg5wYishB8",
        "outputId": "75e00505-155e-46a9-a4bf-6a1c98db598a"
      },
      "source": [
        "def func_generator():\n",
        "    model_gen = tf.keras.Sequential()\n",
        "    number_nodes = 7 * 7 * 256\n",
        "    model_gen.add(layers.Dense(number_nodes, use_bias=False, input_shape=(100,)))\n",
        "    model_gen.add(layers.BatchNormalization())\n",
        "    model_gen.add(layers.LeakyReLU(alpha=0.1))# Negative slop cefficient\n",
        "\n",
        "    model_gen.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model_gen.output_shape == (None, 7, 7, 256) \n",
        "\n",
        "    model_gen.add(layers.Conv2DTranspose(128, kernel_size=(3, 3), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model_gen.output_shape == (None, 7, 7, 128)\n",
        "    model_gen.add(layers.BatchNormalization())\n",
        "    model_gen.add(layers.LeakyReLU(alpha=0.1))\n",
        "\n",
        "    model_gen.add(layers.Conv2DTranspose(64, kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model_gen.output_shape == (None, 14, 14, 64)\n",
        "    model_gen.add(layers.BatchNormalization())\n",
        "    model_gen.add(layers.LeakyReLU(alpha=0.1))\n",
        "    \"\"\"\n",
        "    All the activation functions will be LeakyReLU in the layers,\n",
        "    but last layer activation will always be \"tahn\"\n",
        "    \n",
        "    \"\"\"\n",
        "    model_gen.add(layers.Conv2DTranspose(1, kernel_size=(3, 3), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model_gen.output_shape == (None, 28, 28, 1)\n",
        "\n",
        "    return model_gen\n",
        "\n",
        "\n",
        "gen = func_generator()\n",
        "input_noise = tf.random.normal(shape=[1, 100])\n",
        "gen_img_out = gen(input_noise, training=False)\n",
        "plt.imshow(gen_img_out[0, :, :, 0])\n",
        "# print(gen_img_out.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa6f069c650>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbZUlEQVR4nO2de3CdZ3Xun6X7/WZLsmz5fontOI6dGJMbJBAIxiFX5qSEFpwhh+SckqHQTqeUM1OYnukpw5AwnU4KNcXFtDRtSkJJOGlIYgK5cBKs+G58jSPZukuWZEuyrOt7/tA2Y0Dr2UaS99b0fX4zGkn70bu/d3/f9+jb+1vvWstCCBBC/NcnI90TEEKkBpldiEiQ2YWIBJldiEiQ2YWIhKxUbiy7tCDkVJe6erLAQAjmajlZo3Ts0Egm1fOzh6mel+HrvcN5dGxu5gjV+4dzqJ6RwXdMpo252uAwP8TJnpvt8/Hx/rYBYGzMv57kZPH9MjiUTfWsJMc8k8wt2XOX5Z+jet9ILtULsoao3jvonzNZmfx1jZFjMtR+BiNnzk34B1Myu5ltAvA3ADIB/EMI4Svs73OqS7Hmb7f4E01iyPPkAC2e1UXHNnSXU/3Kqlaqryry9ZfbVtCxS0s6qb6zdT7VC3P5iVOU4+v1bbPo2Jxc/k9ueIifIkWF56ne1++f1Aur+DE73lBN9crqM1SvIIY9enIOHXvPVbup/nrbEqpfU9lI9R0n/HOmsrSPjh0g/8CPfG6bq036bbyZZQJ4HMCHAawGcL+ZrZ7s8wkhLi9T+cy+EcDxEMKJEMIQgH8FcNf0TEsIMd1MxezzAJy66PfGxGO/hpk9ZGZ1ZlY3coZ/DhJCXD4u+934EMLWEMKGEMKGrNKCy705IYTDVMzeBODiO0u1iceEEDOQqZh9J4DlZrbYzHIAfAzAM9MzLSHEdDPp0FsIYcTMHgHwY4yH3raFEA7yMTy8NjLKQ2/F+YOudriZh2nmVJyl+i/eXkT1jKV+PPpkMw9vDZNYMwD0ni6k+r/d+m2qf+TpP3a1JVfzN1tnzvM1AsvmNFN9d3Mt1XPz/NBeY1cZHbtkQTvVm7r8NRsAUJrnhwWz83nIMRl953mc/acNy6heUdLvanfM20/H/v1b73W1UeKvKcXZQwjPAXhuKs8hhEgNWi4rRCTI7EJEgswuRCTI7EJEgswuRCTI7EJEgqWyumzJFdXhXd/8fVc/2cnTUMfq/Xh00cpuOra6uJfqx1srqZ57wF/qm3vdaTq2u62E6khyCIqP8Nzrubc3uFqyvOoDTXOpnr2frwGYdXML1U81+WsQiiv8WDMAhNf4+bD+oweovus/1rjagk31dGzDC4uonns9P+aZSeoEsPUmGS/w1114p59uve+R7eg72jphPruu7EJEgswuRCTI7EJEgswuRCTI7EJEgswuRCSktJT0WDAMDPthJDMerii4osfVcrN5WeKibD89FgBGB/iuuPYOP8xzsreCjh2axctxnevj6ZJ9V/PSwmdIWWKmAUB2Dt9vQ2v43LOTlD3+8+v9pMht79xAx/Zez6vH9gzxykc1t51ytWQhyXMr+PmytJTP7fQAn1tnR7GrlX2IV90dJaWkA3xNV3YhIkFmFyISZHYhIkFmFyISZHYhIkFmFyISZHYhIiGlcXYzHpdN1jF0sMePGQ+V826ibc28bPG8Wh7bfP34UldbVMPTHZNRXDJA9bNJSk1nkPUJq8vb6Nif9fCSx1fV8lLUtQX+2gcA+MZRv+xx7zF+TLIX8hTYZLHseUV+LPyt+gV0LEb4dbAkm59vBxp46vB9695ytX/fey0di3J/v7AW27qyCxEJMrsQkSCzCxEJMrsQkSCzCxEJMrsQkSCzCxEJKY2zZ9oYinP8PGHzQ4QAgHuv9WOTz9ev4oPH+JMny8v+zPqfudrje26mY69f8g7V97XXUH3VEt42+ShpV/3XK56mY187uYTqd1btpfpfvnEH1S1rzNX+dPOzdOy/NW2ges+5fKoP5fund9Us3sK7rYO3g65rnE/1ZDxXv9rV/tvV/nkOAE/9cr2rjY765/mUzG5m9QB6AYwCGAkh8KMjhEgb03Flf18IoXMankcIcRnRZ3YhImGqZg8AXjCzt8zsoYn+wMweMrM6M6sb6uFrwIUQl4+pvo2/KYTQZGZVAF40s8MhhFcu/oMQwlYAWwGgbGVV6hrLCSF+jSld2UMITYnv7QB+AGDjdExKCDH9TNrsZlZoZsUXfgZwGwDeVlMIkTYm3bLZzJZg/GoOjH8c+JcQwl+xMUUr5oR1j3/S1RuPVPFtlvu1vmdV9NGxVYVcbz7L2yr3dBW5WmYOj9FnHeF519U38jj62ON8vzTfN+xqo+f4J7WKObz+uf2H33IZAPo38f1alO+vqxhNtvbh+7wef8mWRqp3P1HraoO389ed/QKPs49+iOfxn23168IDwIrl/jE//S88hl/7yROu9sqnn0TP4fYJd+ykP7OHEE4AuHqy44UQqUWhNyEiQWYXIhJkdiEiQWYXIhJkdiEiIaUprqNjGejq98NQ+fN4GGdWkd8+eIyU0AWAyjz+3MfaKqmeU+CH/VZUd9CxBQt5e+A3D/M00+qHeZnr6gw/jTSvmrdkbj3DQ0TDH+TlnNkxAXg556Y+Ht7quYMfszOneSnqoXX+filK0h78zI28VPQVSVo2VxTy/fJOux/SHH43P2YDnbNdbXDEt7Su7EJEgswuRCTI7EJEgswuRCTI7EJEgswuRCTI7EJEQkrj7ABgNL7JY+WsNXFtEU85fP0na6i+9j3HqH6i24+LnjidJA20h5c8fv+Vh6n+8s4rqb5yzSlXa+vzU3MBIDebx3QXVnRTvaOfP3/7o/4agrVf3E/HvnSIJ1W++91HqP7/zvB21IzQlUP1+jyefru6upXqDUP+OXPbOl4Woumcv76gOctPt9aVXYhIkNmFiASZXYhIkNmFiASZXYhIkNmFiASZXYhISGmcPTtzFHNKel39nVY/TxcA2kb9/01NnTy3eSyP5y83nOFx0++s3e5qd+14hI5dv7yB6j87wePBj236HtU//9LHfTHXz+kGgCsWtVD9hll+2WIA2N5yHdUHH/CP9wt1V9GxP7r361T/2O4HqX7jlf7aidcPLKdjn7uTb/trrbdRfU/HXKrnF/kltufm8lz5Vxr882VwWPnsQkSPzC5EJMjsQkSCzC5EJMjsQkSCzC5EJMjsQkTCpFs2T4bK1bPC3d+93dV/3rSYjj/Xl+tqNZU8NlmWN0D1g8f89r4AkN3hxy/v2vQGHfuTb/JY9JmbeY3yRd/ief5rHt3nakfP8nbPhw/w9sC5HZlUD2v8ODoAZGb6cf7hYf7cJS8VUn3lpw5RncbS+S7FvB/z62DGp9up3thWTvVrFp90tZa/5esuiv+HX7/gjYefwNkjbRO+uqRXdjPbZmbtZnbgoscqzOxFMzuW+M5fmRAi7VzK2/jvANj0G499AcCOEMJyADsSvwshZjBJzR5CeAXAb/YfugvAhfWj2wHcPc3zEkJMM5O9QVcdQriwqLoVQLX3h2b2kJnVmVnd+W5/PbAQ4vIy5bvxYfwOn3uXL4SwNYSwIYSwIa/cv8EmhLi8TNbsbWZWAwCJ7/zWpBAi7UzW7M8A2JL4eQuAH07PdIQQl4uk+exm9gSAWwDMNrNGAF8C8BUAT5rZgwAaANx3KRvrHcrFqyeXuvrwEJ9OVo5fE/vsef4RoamB13ZHJl9vMFzmb/ulU1fQsT3v4rXZ51ScpfqJe3jv+KFOP1a+oJjXfS+s5XHy/tI8qteU8P7tS0s7Xa2uaQEde+9nf0L1Z5t4L4DMs34cf/Mtb9GxzSt57/iW/hKql5Xx/fJOj18/Yeh+fj6c7/fXH4yM+dfvpGYPIdzvSLcmGyuEmDlouawQkSCzCxEJMrsQkSCzCxEJMrsQkZDSUtJhLAPnz/mtcItLeBoqC44NDmbTsQWzz1G9OJ8v5W1r8UtVs3AHACxZ3Eb1xtO8DHb2HD739jN+2+TGIzzF9X0bD1L97UJe3jtZyPPVvStdraCSh6e2/fj9VMdcnhpc2OQfl9dbeDp1/y7+unOv5iHNzAxewrv7HT9RdOO1vH346fN+6C2LbFdXdiEiQWYXIhJkdiEiQWYXIhJkdiEiQWYXIhJkdiEiIaVx9szMUZSX97l6VztPG8wuGHa1sSSx7gWzeVy0sYvHuv/+Zr9l82d3fYyO7ejjJZGzsvz0WQBYOvs01Q81zXG1kmO8XPMb8xZSvbyQr304c6aA6n/9vn93tceOf4CO/dM7nqL6N0+8l+o95X56blUBf13ff+CrVH//C5+n+vwFfmovAMxd65eSzsngKdFvN/kpz4PD/noTXdmFiASZXYhIkNmFiASZXYhIkNmFiASZXYhIkNmFiISUtmzOWzovLPzqw64+OpKkTS5p/5uVxfOHzw/4efQAsG6B3wYXAJof99votnyAx0Uth88tI0kZ6/n/xJdDtHzKz+vOequYjj1fyee24AX+2qq+dILqv6hb4WpZVTzWXfmDfKr3fZy36e6r98tBj5Xw17XqUV5ie962Rqrv2MnLXBfX+uWi+9/mZaznr21xtV1/+M/oPdI6uZbNQoj/GsjsQkSCzC5EJMjsQkSCzC5EJMjsQkSCzC5EJKQ0nz0rcxSVJX4+e/NpHl9ktd3zs3nctLnJr60OALuD3/YYAMZu8ePRSxa107FZxmPZg6P8MHQ+zHPGbcTPWb/xo7vp2N0dtVRvnMe3XTbK8+XzSUvogSTHpPmDPM9/WbF/LgFAb4Ufpy8s4n0C+h4bovrezrlUt1I+vq/Xz7UP2XzdRSepjzAy6l+/k17ZzWybmbWb2YGLHvuymTWZ2Z7E1+ZkzyOESC+X8jb+OwA2TfD410MI6xJfz03vtIQQ001Ss4cQXgHQlYK5CCEuI1O5QfeIme1LvM13G1eZ2UNmVmdmdSNn+FpoIcTlY7Jm/waApQDWAWgB8Kj3hyGErSGEDSGEDVmlPLFBCHH5mJTZQwhtIYTREMIYgG8B2Di90xJCTDeTMruZ1Vz06z0ADnh/K4SYGSSNs5vZEwBuATDbzBoBfAnALWa2DuMt0+sB+EnqFzE8lIVT9X7f69xy3m+7q9mPwy9awmPda9Y2UP3w67xf91iZH/M9R2p1A0Bri9+LGwCuWspzo5OtP5g7y8/rfv3p9XRs/k28vvmGBX59cwA41FlN9aG3/V4AVWs66NjZBbx/e/NZ3mcgg9Q4qC3roWOPnvRr8QPA0vn8fBstmzCl/Fcsr/D3+5tHltCxJfm+T1hf+KRmDyHcP8HD3042Tggxs9ByWSEiQWYXIhJkdiEiQWYXIhJkdiEiIaUprpYZaHitrIgvp715+X5Xe3L3Bjp2/TIeerv/9leo/v3j61yttZW3e16xsJXqY4GHaR5c83OqP9t0lasNr+dpoAsKuf7Jar7t/3noE1QvX+mnVbR38NDZxiv5MTu0i7ebXna1H9JsOsPDmX9x3bNU/6sffpTqeSt4meudO/0S25bFU1wHhvxQLzuXdGUXIhJkdiEiQWYXIhJkdiEiQWYXIhJkdiEiQWYXIhJS2rK5YPncsPyxB129/1wuHT/W7Fe6mb2Kp2rmZfFS0437eUpj+QE/fnn6fbwsMZLs4hXz26g+8pc8jXTO//HbJjd87Qo6tm8LjwdX3XWY6jfs5SWTt++9zhfP8tTghT/iJbiL/5y32W7v90tVdxz1U60BYKyQl7EuruTrE/pP8Dj+h96zx9V+8p88LXn2Rv982ffIdvQdVctmIaJGZhciEmR2ISJBZhciEmR2ISJBZhciEmR2ISIhpfnsmTaGUlIG99z5HDqexdL7zvMYfUd/MdVLl3dTvXe+P7fZhbwEdjKOHJ3H/+A+LucN+esPzn+Kv66eFh4PHnjSz5UHgK5TfI1BTZVfsrkl8DoADbfzOPzKMX6t6uzx4+wLrmyhY08eqKH6ipW8DPbJJC3Enz94pauF2mE6NjvTXwNgpDSCruxCRILMLkQkyOxCRILMLkQkyOxCRILMLkQkyOxCREJK4+w5maOoLfLjro0dvLVx74AfS2fxRQCw1jyqF1TyvO7uDj9O35fBE9Zrys5Sff01fj18AOgd5nM/3uPnZl9RwVsLzy/hcfinl71I9bW/mKjJ76VRO4dvuzWXr40YHOWnb2GBvwagq7+Ajp2ziu+3Ay08Dj+7hLebvueq3a727FG+tmGAtAifUt14M5tvZi+b2S/N7KCZ/VHi8Qoze9HMjiW+c6cKIdLKpbyNHwHwJyGE1QCuA/AZM1sN4AsAdoQQlgPYkfhdCDFDSWr2EEJLCGFX4udeAIcAzANwF4DtiT/bDuDuyzVJIcTU+Z1u0JnZIgDrAbwJoDqEcGGBcSuACQulmdlDZlZnZnXne6a2hlwIMXku2exmVgTgKQCfCyH82h2nMF61csK7VCGErSGEDSGEDXll/EaTEOLycUlmN7NsjBv9eyGEpxMPt5lZTUKvAcBvXwoh0krS0JuZGYBvAzgUQnjsIukZAFsAfCXx/YfJnmtgJBsHO/ySzVlJ0gJvXXjU1Z4/voqOzVncS/XTvYVUv3fdLld7o2MRHbugiIeYXmlYRvUPLTlE9Te7/O3//O0KOnbxap7qecsBfiumt5uHsArn+KHWU/W8nPPhj/wd1dd+57NUv+HWA672ev1iOvbuxfuo/rOM5VRv2s1Dcz8oqnS1LTe9Ssc+ceRaVxsd9a/flxJnvxHAJwDsN7MLxa6/iHGTP2lmDwJoQNKsayFEOklq9hDCawC8SP2t0zsdIcTlQstlhYgEmV2ISJDZhYgEmV2ISJDZhYiElLZszl82Nyx77L+7+tkkMdvM035qX94SHkc/1+yXFQaAkMvbAxec8Ldd+4GTdGzLcwuo3j+fb7vsEM/f7b7BT+XMO8pXLYZ1fL/ZHp5m+r+3/DPVH/2Lj7vayCdO07EDL/uxaAAofD9fx9V+Ypar1SzjpaDDP1ZRPefBVqq3vTaX6oNVfjnoij38Gjz8EX/twvE//gcMHG9Wy2YhYkZmFyISZHYhIkFmFyISZHYhIkFmFyISZHYhIiGlpaRDMAwM+K2PS8rP0fHDxZmuVlPKyzVnlPJS0V0DPMZ/etAvnmvG1ypUbz5F9c4+nkvfA97aeGmtHzMemcv/nzd38ZbNI5V8DcATbRup3n6nX4qMZ9oD/Yv8WDQAVOUMUf2Ga4642s4dvP7B8Hv4695QwNcndK7j59vm+cdd7fnz6+nYNeVdrnYqy68JoSu7EJEgswsRCTK7EJEgswsRCTK7EJEgswsRCTK7EJGQ0jh7MhaT+CEA7GuY52rFVby11O6DvE74Vat5TnrZqgFXO9Hu500DwEhHPtVnL+Gv+6r171C9Mq/P1V798Vo6dnTp1FpytfSX8Oc/66+r2Lic18N/vofXIDhRz3PO247XutoVHz5Bxx5p5c9dms33W2mBf74AwP/d67dlvu29e+nYvZ2+D4bH/LUourILEQkyuxCRILMLEQkyuxCRILMLEQkyuxCRILMLEQmX0p99PoDvAqgGEABsDSH8jZl9GcCnAVxIpv5iCOE5/lwBefl+DjKLowNATZVfL3vP3iV07O3X7aH6T0/xHumzi/pdbbjPjyUDwNzlvEZ522meU37n/P1U/8e917vasht5Lv3xvX4sGgB+dO9jVL/92c9T/eubvudqn3/t9+jYrFyez56MjOu6Xe3gSd4//RvX83r4D7/8ANVvvPIY1UdJnYGfvsN7vw+3++s2Rs77lr6URTUjAP4khLDLzIoBvGVmLya0r4cQvnYJzyGESDOX0p+9BUBL4udeMzsEgF+ChRAzjt/pM7uZLQKwHsCbiYceMbN9ZrbNzCas22RmD5lZnZnVjZ7lZaeEEJePSza7mRUBeArA50IIZwF8A8BSAOswfuV/dKJxIYStIYQNIYQNmSW8zpsQ4vJxSWY3s2yMG/17IYSnASCE0BZCGA0hjAH4FgBeeVAIkVaSmt3MDMC3ARwKITx20eMX3868B8CB6Z+eEGK6SNqy2cxuAvAqgP0ALtTX/SKA+zH+Fj4AqAfwcOJmnkvRijlh3eOfdPWhUT89DwDamv2Syu9aydNAD7bNobrxrsg41+SnW2ZX8XTG0v/kpaKL/6CJ6n3f5fdDuzf7YcFQz7eds5yX4B46zlNYs5fyksrlRf59mq43+DEprufnZs8m/3UDwHC33646o2iYji15k6clF3wkScvmLr7fcnP97ee+yMcu+4OjrrbjU0+h+3DHhGfzpdyNfw3ARINpTF0IMbPQCjohIkFmFyISZHYhIkFmFyISZHYhIkFmFyISUlpKemQ0E63dxa4exvj/nuwiPz322OlKOjYni6dLDg7zXZE/1y/XnOy5qx7gKa4N3X47aAAY2MTj+CUFg6429zq+7aMtvGRybpI4/LwkrbDzs/x4cucqf58CQHcBXyNQU85j/HPnN7rakU7+ulfdX0/1/e08RXbZnCT7/aS/xmDWPTyGPzTqn6thwij5OLqyCxEJMrsQkSCzCxEJMrsQkSCzCxEJMrsQkSCzCxEJSfPZp3VjZh0AGi56aDaAzpRN4Hdjps5tps4L0Nwmy3TObWEIYcJFJyk1+29t3KwuhLAhbRMgzNS5zdR5AZrbZEnV3PQ2XohIkNmFiIR0m31rmrfPmKlzm6nzAjS3yZKSuaX1M7sQInWk+8ouhEgRMrsQkZAWs5vZJjM7YmbHzewL6ZiDh5nVm9l+M9tjZnVpnss2M2s3swMXPVZhZi+a2bHEd54Mn9q5fdnMmhL7bo+ZbU7T3Oab2ctm9kszO2hmf5R4PK37jswrJfst5Z/ZzSwTwFEAHwTQCGAngPtDCL9M6UQczKwewIYQQtoXYJjZewH0AfhuCGFN4rGvAugKIXwl8Y+yPITwZzNkbl8G0JfuNt6JbkU1F7cZB3A3gAeQxn1H5nUfUrDf0nFl3wjgeAjhRAhhCMC/ArgrDfOY8YQQXgHQ9RsP3wVge+Ln7Rg/WVKOM7cZQQihJYSwK/FzL4ALbcbTuu/IvFJCOsw+D8Cpi35vxMzq9x4AvGBmb5nZQ+mezARUX9RmqxVAdTonMwFJ23inkt9oMz5j9t1k2p9PFd2g+21uCiFcA+DDAD6TeLs6Iwnjn8FmUuz0ktp4p4oJ2oz/inTuu8m2P58q6TB7E4D5F/1em3hsRhBCaEp8bwfwA8y8VtRtFzroJr63p3k+v2ImtfGeqM04ZsC+S2f783SYfSeA5Wa22MxyAHwMwDNpmMdvYWaFiRsnMLNCALdh5rWifgbAlsTPWwD8MI1z+TVmShtvr8040rzv0t7+PISQ8i8AmzF+R/5tAP8rHXNw5rUEwN7E18F0zw3AExh/WzeM8XsbDwKYBWAHgGMAXgJQMYPm9k8Yb+29D+PGqknT3G7C+Fv0fQD2JL42p3vfkXmlZL9puawQkaAbdEJEgswuRCTI7EJEgswuRCTI7EJEgswuRCTI7EJEwv8HDPBzfVMcm0gAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EP57pCOUtPVa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eddcb925-8d5c-402c-ce07-c21391f8762e"
      },
      "source": [
        "def func_discriminator():\n",
        "    model_disc = tf.keras.Sequential()\n",
        "    model_disc.add(layers.Conv2D(128, (3, 3), strides=(2, 2), padding='same',\n",
        "                                     input_shape=[28, 28, 1]))\n",
        "    model_disc.add(layers.LeakyReLU())\n",
        "    model_disc.add(layers.Dropout(0.3))\n",
        "\n",
        "    model_disc.add(layers.Conv2D(256, (3, 3), strides=(2, 2), padding='same'))\n",
        "    model_disc.add(layers.LeakyReLU())\n",
        "    model_disc.add(layers.Dropout(0.3))\n",
        "\n",
        "    model_disc.add(layers.Flatten())\n",
        "    model_disc.add(layers.Dense(1))\n",
        "\n",
        "    return model_disc\n",
        "\n",
        "\n",
        "disc = func_discriminator()\n",
        "disc_out = disc(gen_img_out)\n",
        "print (disc_out)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor([[-0.00109579]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhzwjzfWwNNr"
      },
      "source": [
        "# calcululating loss to compute true values and  predicted values\n",
        "loss_crossEntropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def loss_gen(img_fk_out):\n",
        "    return loss_crossEntropy(tf.ones_like(img_fk_out), img_fk_out)\n",
        "\n",
        "def loss_disc(img_rl_out, img_fk_out):\n",
        "    loss_rl_img = loss_crossEntropy(tf.ones_like(img_rl_out), img_fk_out)\n",
        "    loss_fk_img = loss_crossEntropy(tf.zeros_like(img_fk_out), img_fk_out)\n",
        "    loss = loss_rl_img + loss_fk_img\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_XXsSvIdyT_u"
      },
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
        "checkpoint = tf.train.Checkpoint(gen_optimizer=tf.keras.optimizers.Adam(1e-4), disc_optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "                                 generator=gen, discriminator=disc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHz9os-I2q2U"
      },
      "source": [
        "dim_Noise = 100\n",
        "EPOCHS = 10\n",
        "samples = 20\n",
        "\n",
        "# You will reuse this seed overtime (so it's easier)\n",
        "# to visualize progress in the animated GIF)\n",
        "seed = tf.random.normal([samples, dim_Noise])\n",
        "\n",
        "@tf.function # executes the compilation of the model\n",
        "def train_step(images):\n",
        "    noise = tf.random.normal([batch, dim_Noise])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      gen_img_out = gen(noise, training=True)\n",
        "\n",
        "      img_rl_out = disc(images, training=True)\n",
        "      img_fk_out = disc(gen_img_out, training=True)\n",
        "\n",
        "      generatorLoss = loss_gen(img_fk_out)\n",
        "      discriminatorLoss = loss_disc(img_rl_out, img_fk_out)\n",
        "\n",
        "    genGradients = gen_tape.gradient(generatorLoss, gen.trainable_variables)\n",
        "    discGradients = disc_tape.gradient(discriminatorLoss, disc.trainable_variables)\n",
        "\n",
        "    gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "    disc_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "    gen_optimizer.apply_gradients(zip(genGradients, gen.trainable_variables))\n",
        "    tf.keras.optimizers.Adam(1e-4).apply_gradients(zip(discGradients, disc.trainable_variables))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HhMCiwY3NT6"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFLgsbMEeVTy"
      },
      "source": [
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time()\n",
        "\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "\n",
        "    # Produce images for the GIF as you go\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator,\n",
        "                             epoch + 1,\n",
        "                             seed)\n",
        "\n",
        "    # Save the model every 15 epochs\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "\n",
        "    print ('Time for epoch {} is {} sec'.format(epoch + 1, time.time()-start))\n",
        "\n",
        "  # Generate after the final epoch\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator,\n",
        "                           epochs,\n",
        "                           seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9aIDZzKrELK"
      },
      "source": [
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  # Notice `training` is set to False.\n",
        "  # This is so all layers run in inference mode (batchnorm).\n",
        "  predictions = model(test_input, training=False)\n",
        "\n",
        "  fig = plt.figure(figsize=(6, 6))\n",
        "\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(4, 5, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifYHc6wC9C_y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        },
        "outputId": "bb16562b-67ba-44a9-df6b-07670e345689"
      },
      "source": [
        "train(X_train, EPOCHS)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-f3637d42f0d4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-9da6986ae9e4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(dataset, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimage_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# Produce images for the GIF as you go\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    <ipython-input-14-76691a85265c>:28 train_step  *\n        gen_optimizer.apply_gradients(zip(genGradients, gen.trainable_variables))\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:604 apply_gradients  **\n        self._create_all_weights(var_list)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:781 _create_all_weights\n        _ = self.iterations\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:788 __getattribute__\n        return super(OptimizerV2, self).__getattribute__(name)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:926 iterations\n        aggregation=tf_variables.VariableAggregation.ONLY_FIRST_REPLICA)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:1132 add_weight\n        aggregation=aggregation)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py:810 _add_variable_with_custom_getter\n        **kwargs_for_getter)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py:142 make_variable\n        shape=variable_shape if variable_shape else None)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:260 __call__\n        return cls._variable_v1_call(*args, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:221 _variable_v1_call\n        shape=shape)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py:67 getter\n        return captured_getter(captured_previous, **kwargs)\n    /usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py:731 invalid_creator_scope\n        \"tf.function-decorated function tried to create \"\n\n    ValueError: tf.function-decorated function tried to create variables on non-first call.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K31CL_hOk3e"
      },
      "source": [
        ""
      ]
    }
  ]
}